前段时间同事在作一个新项目的时候用到了lua_cjson.c这个库(以下简称cjson)，
将json串转换成lua本地的数据结构,但是在使用的过程中出现了中文乱码问题，
奇怪的是只有那么几个字是乱码，这其中就包括"朶"字，其他字一切正常。经了解
json串用的是GBK编码，那问题就来了，为什么用gbk编码会出现这个问题，原因是
什么？又应该怎么解决这个问题？

要解释清楚这个问题，首先我们来看看json串都有哪些要求。

json全称JavaScript Object Notion是结构化数据序列化的一个文本，可以描述
四种基本类型(strings,numbers,booleans and null)和两种结构类型(objects 
and arrays)。

RFC4627中有这样一段话:

   A string is a sequence of zero or more Unicode characters.
   字符串有零个或多个unicode字符序列组成.

在这里稍微解释下什么是unicode字符。我们都知道ascall字符有字母、数字等,但是
他收录的字符只有一百多个。比如汉字就不是ascall字符，但是unicode收录了汉字
,所以汉字可以是unicode字符。这里要说明的是unicode字符其实就是一些符号。

现在另一个问题出来了，在json文本中应该怎么表示这些字符.
在规范的Encoding片段是这样说的:

   JSON text SHALL be encoded in Unicode. The default encoding is UTF-8。
   JSON文本SHALL把unicode字符编码。默认使用utf-8编码。

我们看到在这里用到了SHALL[RFC2119]这个关键字,也就是说字符必须被编码后才能
作为json串使用,而且默认使用utf-8编码。如何判定使用的是那种unicode编码?
看下面一段话:

   Since the first two characters of a JSON text will always be ASCII
   characters[RFC0020], it is possible to determine whether an octet
   stream is UTF-8、UTF-16(BE or LE), or UTF-32(BE or LE)by looking at
   the pattern of nulls in the first four octets.

   由于json文本的前两个字符(注意这里说的是字符,不是字节)一定是ASCII字符,
   因此可以从一个字节流的前四个字节(注意是字节)中判断出该字节流是UTF-8、
   UTF-16(BE or LE)、or UTF-32(BE or LE)编码。 
	
   00	00	00	xx	UTF-32BE  (u32编码大端)
   xx	00	00	00	UTF-32LE  (u32编码小端)
   00	xx	00	xx	UTF-16BE  (u16编码大端)
   xx	00	xx	00	UTF-16LE  (u16编码小端)
   xx	xx	xx	xx	UTF-8	  (utf-8编码)   
    
   ps:
     u32用32位的4字节整数表示一个字符；

     u16用16位的2字节整数表示一个字符,如果2字节表示不了,就用连续两个16位的
	 2字节整数表示，所以就会出现u16编码中有4个字节表示一个字符的情况，和u32
     的四字节不一样的是,该字符在u16中的前两个字节和后两个字节之间不会有字序
	 的问题。
     
     utf-8用多个8位的1字节序列来表示一个字符,所以没有字序的问题.

截止到现在我们没有看到任何关于可以使用GBK编码的信息,难道json文本就不能用gbk编码,
如果真的不能用的话，那为什么cjson不是把所有的gbk编码解释称乱码,而是只有某几个字
是乱码。在规范中对json解析器有这样一段描述:

   A JSON parser transforms a JSON text into another representation.
   A JSON parser MUST accept all texts that conform to the JSON grammar.
   A JSON parser MAY accept non-JSON forms or extensions.
   
   json解析器可以将一个json文本转换成其他表示方式。
   json解析器MUST接受所有符合json语法的文本.
   json解析器MAY接受非json形式或扩展的文本.

从规范对解析器的描述可以看到,规范并没有要求解析器必须对文本的编码方式做校验,
而且解析器也可以有选择的去接受非json形式的文本。

现在我们再来看看cjson解析器是如何做的，在cjson开头的注释中说了这么一句话:
    Invalid UTF-8 characters are not detected and will be passed untouched。
    If required, UTF-8 error checking should be done outside this library。
    发现无效的UTF-8编码会直接放过,如果有必要对UTF-8编码的检查应该在该库的之外。
说的很清楚,对非utf8编码直接放过，不做任何检查,所以用gbk编码不符合规范,但又可以
被解析的答案就出来了。那"朶"等这些字的乱码问题又是怎么回事? 我们现在看看cjson
对规范中的另外两个编码utf16、utf32是如何做的，然后再说乱码问题.

在cjson解析方法的开始处是这么做的:
    /* Detect Unicode other than UTF-8(see RFC 4627, Sec 3)
     *
     * CJSON can support any simple data type, hence only the first
     * character is guaranteed to be ASCII (at worst:'"'). This is
     * still enough to detect whether the wrong encoding is in use.
     */
    if (json_len >=2 && (!json.data[0] || !json.data[1]))
       luaL_error(1,"JSON parser does not support UTF-16 or UTF-32");
前面我们说过一个json串的前两个字符一定是ascall字符,也就是说一个json串至少也的有两个
字节.所以这段代码首先判断json串的长度是不是大于等2,然后根据串的前两个字节的值,是否
有零来判断该文本是否是非utf-8编码。结果已经看到了，人家不支持规范上说的u16和u32编码.

现在我们就来看看"朶"这个子是如何变成乱码的，经过对cjson源码的分析得知,cjson在处理
字节流的时候当遇见'\'反斜杠时会猜测后一个字节应该是要被转义的字符,比如\b、\r之类
的字符,如果是就放行,如果不是,cjson就认为这不是一个正确的json格式,就会把这个字节和
前面的'\'反斜杠一块给干掉,所以本来用两个字节表示的"汉"子就硬生生的给掰弯了。

那"朶"字跟'\'反斜杠又有什么关系? 这两个字符在GBK和ASCALL中编码如下:
    "朶" 0x965C
    "\"	 0x5C
这样我们就看到"朶"字的低位字节和"\"字符相同,都是0x5C,如果这时候"朶"字后边不是
b、r之类的ascall字符,cjson就会把这个字节和紧跟其后的一个字节抹掉,所以乱码就产生了。

那我们应该怎么解决这个问题,让cjson可以顺利的支持gbk编码呢,首先我们看看gbk编码
是怎么回事,为什么会出现低位字节和ascall冲突的问题.

先来了解一下GB系列的编码范围问题:
GB2312(1980)共收录7445个字符，6763个汉字和682个其他字符。
每个汉字及符号用两个字节表示,为了跟ascall兼容,处理程序使用EUC存储方法。
 汉字的编码范围
   高字节: 0xB0 - 0xF7,
   低字节: 0xA1 - 0xFE,
 占用72*94=6768,0xD7FA - 0xD7FE未使用。

GBK共收录21886个字符,采用一字节和双字节编码。
  单字节表示范围
    8位: 0x0 - 0x7F
  双字节表示范围
    高字节: 0x81 - 0xFE
    低字节: 0x40 - 0x7E、0x80 - 0xFE

GB18030收录70244个汉字,采用1、2、4字节编码。
  单字节范围
    8位: 0x0 - 0x7F	
  双字节范围
    高字节: 0x81 - 0xFE
    低字节: 0x40 - 0xFE
  四字节范围
    第一字节:0x81 - 0xFE
    第二字节:0x30 - 0x39
    第三字节:0x81 - 0xFE
    第四字节:0x30 - 0x39

由于GB类的编码都是向下兼容的,这里就有一个问题,因为GB2312的两个字节的高位
都是1,符合这个条件的码位只有128*128=16384个。GBK和GB18030都大于这个数,所
以为了兼容,我们从上面的编码范围看到,这两个编码都用到了低位字节的最高位可
以为0的情况,所以GBK的低位字节就合ascall发生了冲突。

最终得出的结论就是,在GBK编码中只要该字符是两个字节表示,并且低位字节是0x5C
的字符都会被cjson弄成乱码.

解决方案:
  1) 不要使用gbk编码,将你的字符串转换成utf-8编码.
  2) 对cjson源码稍微做个改动,就是在每个字节到来之前先判断该字节是否大于127,
   如果大于则将该字节个随后的一个字节放过,否则交给cjson去处理。

===============番外篇(Unicode和UTF-8、UTF-16、UTF-32的区别)=================
unicode只是一个字符集,u8、u16、u32是unicode的一种编码方式.

首先举个简单的例子来说明字符集和编码的区别,比如我现在定义一个字符集它就收录
了"中"、"国"、"人"这三个字符,我们分别用数字1、2、12来表示这三个字符. 
那么对于 1212 这一串数字,我们就由好几种解释,分别是:
   1,2,12    "中国人"
   1,2,1,2   "中国中国"
   12,12     "人人"
   12,1,2    "人中国"
为了解决这个问题我们对这个字符集做一个简单的编码,在每一个字符代表的数字前面
在加一个数字,用来表示这个字符用了几个数字.编码后的三个字符如下:
   11   "中"
   12   "国"
   212  "人"
然后我们对一个经过编码串 1112212 进行如下解释:
  拿到这个串的第一个数字是1,那说明紧跟其后的一个数字代表了一个字符,拿到
  这个数字经和字符集对照,该数字代表"中",依次方法逐一分析可的出编码串
  11 12 212 代表 "中国人"

例子举完了,我们接下来看看UTF-8是如何对unicode编码的
RFC 2279中对UTF-8是这样定义的
 在UTF-8编码中,一个Unicode字符可以使用1到6个字节序列对其进行编码。
 1)单字节字符,字节的高位为0,其他7位用于字符编码.
 2)n节字符(n>1),第一个字节的高n位都为1,紧跟其后n+1位为0。剩下所有
   字节高两位为10,其余没有占用的位均作为该字符的编码。
 
 具体编码规则如下:
     UCS-4范围(16进制)		UTF-8(二进制)
   ---------------------------------------------------			
   0000 0000-0000 007F   0xxxxxxx
   0000 0080-0000 07FF   110xxxxx 10xxxxxx
   0000 0800-0000 FFFF   1110xxxx 10xxxxxx 10xxxxxx

   0001 0000-001F FFFF   11110xxx 10xxxxxx 10xxxxxx 10xxxxxx
   0020 0000-03FF FFFF   111110xx 10xxxxxx 10xxxxxx 10xxxxxx 10xxxxxx
   0400 0000-7FFF FFFF   1111110x 10xxxxxx ... 10xxxxxx
  
RFC 3629对UTF-8做了重新规范
 编码规则没变，只是从原来的1到6个字节对unicode编码，变为只能使用
 1到4个字节对unicode进行编码.
 也就是编码范围变成了U+0000到U+10FFFF

 具体编码规则如下:
     UCS-4范围(16进制)		UTF-8(二进制)
   ---------------------------------------------------			
   0000 0000-0000 007F   0xxxxxxx
   0000 0080-0000 07FF   110xxxxx 10xxxxxx
   0000 0800-0000 FFFF   1110xxxx 10xxxxxx 10xxxxxx
   0001 0000-001F FFFF   11110xxx 10xxxxxx 10xxxxxx 10xxxxxx
 
 编码过程如下:
   1)根据要编码的unicode代码点值,确定出要使用的utf-8字节个数n。
   2)设置n个字节中每个字节的高位,其余标记为x。
   3)从unicode值的最低位开始,依次放入到2)中标记为x的地方,x也是从
     最低位开始,未使用的x用0填充。
 
 http://www.unicode.org/charts/PDF/U4E00.pdf中可查看汉字代码点.

 将"中"字(4E2D,100 111000 101101)编码为UTF-8过程如下:  
    1)由4E2D可知中字值范围在 0800 - FFFF间,所以需要3个字节.
    2)3个字节的utf-8编码形式为: 1110xxxx 10xxxxxx 10xxxxxx
    3)从最低位开始填充x,结果为: 11100100 10111000 10101101
 从而可以得出,中字的utf-8编码为E4B8AD

UNICODE转utf-8的例子:
    static int codepoint_to_utf8(char *utf8, int codepoint){
        /* 0xxxxxxx */
        if (codepoint <= 0x7F) {
            utf8[0] = codepoint;
            return 1;
        }
      
   	    /* 110xxxxx 10xxxxxx */
        if (codepoint <= 0x7FF) {
           utf8[0] = (codepoint >> 6) | 0xC0;
       	   utf8[1] = (codepoint & 0x3F) | 0x80;
           return 2;
        }

        /* 1110xxxx 10xxxxxx 10xxxxxx */
        if (codepoint <= 0xFFFF) {
       	    utf8[0] = (codepoint >> 12) | 0xE0;
       	    utf8[1] = ((codepoint >> 6) & 0x3F) | 0x80;
            utf8[2] = (codepoint & 0x3F) | 0x80;
            return 3;
        }

        /* 11110xxx 10xxxxxx 10xxxxxx 10xxxxxx */
        if (codepoint <= 0x1FFFFF) {
            utf8[0] = (codepoint >> 18) | 0xF0;
            utf8[1] = ((codepoint >> 12) & 0x3F) | 0x80;
            utf8[2] = ((codepoint >> 6) & 0x3F) | 0x80;
            utf8[3] = (codepoint & 0x3F) | 0x80;
            return 4;
   	    }

        return 0;
   }


那中文到底在UTF-8编码中用几个字节
 从http://www.unicode.org/charts/PDF/U4E00.pdf可以看到,表示中文最小的
 unicode代码点为4E00,根据以上规则可知,中文在utf-8中最少需要用3个字节表
 示一个字符。

对其他两种编码方式感兴趣的可以去读RFC 2781(UTF-16)和维基百科 (UTF-32)

******************************番外篇(URL编码)***************************
URL编码又称为百分号编码,编码方式很简单,就是把单个字节用16进制表示,然后在
其前面放置一个百分号。
比如有"abc"这样一个串,我们把他转换成ascii的字节序后,用16进制表示成这样:
	61 62 63
把他进行百分号编码就是在各个字节前加上“%”,结果如下:
	%61%62%63 

在URL的表示中并非所有的字符都需要进行百分号编码,RFC3986(URI规范)中规
定保留字符和非保留字符可以不用编码,其它字符必须用百分号编码。
RFC1738(URL规范)规定保留和非保留字符可以直接用于URL中。

保留字符:
	! * ' ( ) ; : @ & = + $ , / ? # [ ]
非保留字符:
	a-z A-Z 0-9 - _ . ~

在一个URL中,如果一个保留字符在特定上下文中有特殊含义,而这个保留字
在URL中又有特殊目的,那么该字符必须百分号编码。
比如"/",在URL中表示路径分隔符,如果某个路径包含该字符,那么在路径内的
该字符就必须进行百分号编码,否则就会和真正的路径分隔符产生歧义.

还有一种需要进行百分号编码的就是”其它字符“,所谓的其它字符就是在
保留字符和非保留字符之外的字符,比如ascii码的非显示字符、汉字字符等。

通过前面我们知道,对一个字符进行百分号编码前需要得到该字符的字节流形式,
也就是说我们需要根据某种字符编码,将该字符转换成字节流,应该用哪种字符编
码(比如GBK、UTF-8等)在RFC1738中并没有给出,所以各个程序(比如浏览器)有自
的方式,但是在2005年1月RFC3986做出了强制规定,强制"其它字符"要先转换为UTF-8
字节序列,然后对其字节值进行百分号编码。
 
对"a中"这个字符串对其百分号编码的过程大概如下:
 1)将串转换成utf-8编码形式的字节流,那么就是0x61 E4 B8 AD
 2)顺序取一个字节,是非保留字?
 3)是,则该字节不用编码,直接输出该字节表示的ascii字符
 4)不是,则证明该字节需要编码，先输出"%"再输出该字节的16进制大写形式
 5)如果还有下一个字节则执行步骤 3),如此循环直到编码完成
 6)最后结果 "a%E4%B8%AD"
 
对"a%E4%B8%AD"串的解码过程如下:
 1)将字符串转变为字节流
 2)顺序取一个字节,标记字节位置为i,比较该字节是否是'%'
 3)不是,直接输出
 4)是,取(i+1)位置字节左移4位 + (i+2)位置字节&0xF ,然后输出
 5)跳过两个字节,如果还有下一字节则执行步骤 3), 如此循环完成解码
 
好，有了上面的知识后我们在看一下浏览器对URL的编码是不是跟规范一样。
首先说下URL的组成:
   {http://www.jd.com[/app/中国]} ? (name=val中) 
   {}:代表URL (绝对URI) 
   []:代表URI (相对URI,这种标示符依赖具体的环境) 
   ():代表Query String 	

直接地址栏中输入,对URI则在IE8、chrome、firefox浏览器上发现都是用UTF-8进行
百分号编码的.
但是对query string,IE8用的是未经过百分号编码的GBK原码(可能用的操作系统的编码);
chrome、firefox上用的是utf-8进行百分号编码。

在网页中嵌套的URL,对于URL的路径部分,IE8、chrom、firefox用的是UTF-8编码
进行百分号编码。
对于query string部分,这三种浏览器采用的是http响应头头中的
  Content-Type:text/html; charset=gbk 指定;
如果未指定则用页面中的
  <meta http-equiv="Content-Type" content="text/html;charset=gbk">指定。

通过以上我们可以知道,各个浏览器对于URL的路径部分使用的编码方式和规范一致,
但是对于Query string部分稍有差别.

另外说下javascript的encodeURI()方法,该方法对保留字符不进行编码,比如以下
字符不进行编码:
  a-z A-Z 0-9  - _ . ! ~ * ' ( ) ; / ? : @ & = + $ , #
所以如果某个URL的数据部分包含特殊的保留字符,用该方法编码该数据后可能无法
区分该字符是数据的一部分还是URL的一部分(比如路径分隔符).

所以javascript就有了encodeURIComponent()方法,从名字上就可以看到该方法对
URL的"成份"进行编码,用它编码后可以明确区分某个字符是"成份"还是URL的特殊
分隔符。







