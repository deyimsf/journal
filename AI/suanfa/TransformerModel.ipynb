{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "4defbe95-09cf-4299-98f2-ceae724d991f",
   "metadata": {},
   "source": [
    "# 一、 ========= model.py =========="
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 208,
   "id": "f848c128-c072-4010-9535-306caf581c08",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "#################### model.py #####################\n",
    "###################################################\n",
    "import math\n",
    "import torch\n",
    "import copy\n",
    "from torch import nn\n",
    "\n",
    "\n",
    "# 嵌入层封装\n",
    "class Embeddings(nn.Module):\n",
    "    # vocab_size: 词表大小\n",
    "    # d_model: 词向量维度\n",
    "    def __init__(self, vocab_size, d_model, padding_idx=0):\n",
    "        super().__init__()\n",
    "        # lookup table Embeding层\n",
    "        self.lut = nn.Embedding(vocab_size, d_model, padding_idx,)\n",
    "        # 词向量维度\n",
    "        self.d_model = d_model\n",
    "    \n",
    "    # 根据词id返回词向量\n",
    "    # x: 入参(句子个数, 句子的id表示)，形状是(句子个数，句子长度)\n",
    "    #    例如: [[1,2,4],[2,4,5]]\n",
    "    def forward(self, x):\n",
    "        assert x.ndim == 2 , '入参形状需要是2维的(句子个数，句子长度)'\n",
    "        \n",
    "        # 返回句子的向量表示,形状(句子个数,句子长度,词向量维度)\n",
    "        # 这里返回的结果，每个元素都乘以了 根号下词向量维度\n",
    "        # 后面对模型词嵌入层参数初始化时，用的方法是xavier,该方法随机初始化参数满足N(0, 1/d_model),乘以 math.sqrt(self.d_model)，可以拉回到 N(0, 1) 分布\n",
    "        return self.lut(x) * math.sqrt(self.d_model)\n",
    "    \n",
    "\n",
    "    \n",
    "# 优化后的位置编码\n",
    "# annotated-transformer\n",
    "class PositionalEncoding(nn.Module):\n",
    "    # max_len: 位置编码最大长度，也是句子长度\n",
    "    def __init__(self, d_model, max_len=5000, dropout=0):\n",
    "        super().__init__()\n",
    "        \n",
    "        # 位置编码为什要加dropout ？？？？？\n",
    "        self.dropout = nn.Dropout(dropout)\n",
    "        \n",
    "        # 初始化位置编码\n",
    "        pe = torch.zeros(max_len, d_model)\n",
    "        \n",
    "        # 位置和除数\n",
    "        position = torch.arange(0, max_len).unsqueeze(1)\n",
    "        div_term = torch.exp(torch.arange(0, d_model, 2) * math.log(10000) / d_model)\n",
    "        \n",
    "        angle = position * div_term\n",
    "        \n",
    "        # 填充pe矩阵值  0::2 从0开始步长是2  1::2 从1开始步长是2\n",
    "        pe[:, 0::2] = torch.sin(angle)\n",
    "        pe[:, 1::2] = torch.cos(angle)\n",
    "        \n",
    "        # pe = torch.linspace(-1,1,max_len).unsqueeze(1)\n",
    "        # pe = pe @ torch.ones(1,max_len)[:,:d_model]\n",
    "\n",
    "        # 同 self.pe = pe  \n",
    "        self.register_buffer('pe', pe) # 表示该值不用梯度更新\n",
    "        \n",
    "            \n",
    "    def forward(self, x):\n",
    "        assert x.ndim == 3 , '入参形状必须是 (batch, sentence_len, d_model)'\n",
    "        \n",
    "        # ## 把某个位置元素设置为0，这个位置是批量入参时的padding  临时功能 #####################\n",
    "        # pe = self.pe[:x.size(1)].masked_fill((x==0), 0)\n",
    "        # return x + pe\n",
    "\n",
    "        #### 正经功能 #####        \n",
    "        # 入参和位置编码相加\n",
    "        # 入参x的形状     (batch, sentence_len, d_model)\n",
    "        # 位置编码形状是   (max_len, d_model)\n",
    "        # 相加的时候位置编码只取 入参的sentens_len(句子长度)长度\n",
    "        # print('PositionalEncoding.forward--> ',x.shape, self.pe.shape)\n",
    "        # print('-->',self.pe[:x.size(1)].shape)\n",
    "        return x + self.pe[:x.size(1)]    \n",
    "    \n",
    "        # 位置编码为什么要加dropout ?????\n",
    "        #return self.dropout(x + self.pe[:x.size(1)])\n",
    "\n",
    "\n",
    "# 封装掩码 \n",
    "# 用来屏蔽批量入参时，句子长短不一致, 批量产生的掩码\n",
    "# 只返回掩码\n",
    "def get_padding_mask(x, padding_idx):\n",
    "    assert x.ndim == 2, '期望维度为2'\n",
    "    \n",
    "    # 入参x形状是 (批次，句子长度), 中间加一个维度，用来和带词向量的入参匹配\n",
    "    # (B,L) -> (B,L,d_model)\n",
    "    return (x == padding_idx).unsqueeze(1)\n",
    "   \n",
    "    \n",
    "\n",
    "# 计算注意力\n",
    "# q、k、v的形状都是(batch,sen_len,d_model)\n",
    "def attention(q,k,v, mask=None, dropout=None):\n",
    "    # 获取q、k、v的最后一个维度,即d_model\n",
    "    d_model = q.size(-1)\n",
    "    # 计算注意力分数 q乘k的转置\n",
    "    scores = torch.matmul(q, k.transpose(-2,-1)) / math.sqrt(d_model)\n",
    "    \n",
    "    # 按照掩码mask对scores进行屏蔽\n",
    "    if mask is not None:\n",
    "        # 列掩码\n",
    "        # print('mask->',mask.shape)\n",
    "        # print('scores->',scores.shape)\n",
    "        scores = scores.masked_fill(mask, -1e9)\n",
    "    \n",
    "    # 用softmax计算出分数的比重\n",
    "    softmax_scores = torch.softmax(scores, dim=-1)\n",
    "    \n",
    "    # dropout\n",
    "    if dropout is not None:\n",
    "        softmax_scores = dropout(softmax_scores)\n",
    "    \n",
    "    # 返回带注意力的数据\n",
    "    context = torch.matmul(softmax_scores, v)\n",
    "    \n",
    "    return context,  softmax_scores\n",
    "\n",
    "\n",
    "\n",
    "# 多头注意力\n",
    "class MultiHeadedAttention(nn.Module):\n",
    "    def __init__(self, d_model, n_head, dropout=0):\n",
    "        super().__init__()\n",
    "        self.norm = nn.LayerNorm(d_model)\n",
    "        self.dropout = nn.Dropout(dropout)\n",
    "        \n",
    "        # 头的数量要可以被词向量维度整除\n",
    "        assert d_model % n_head == 0\n",
    "        # 新头的维度\n",
    "        self.d_k = d_model // n_head\n",
    "        # 新头的个数\n",
    "        self.n_head = n_head\n",
    "        \n",
    "        # q k v多头之前先进行一次线性变换(原论文是先分头再线性变换，实验证明两者差不多)\n",
    "        self.W_Q = nn.Linear(d_model, d_model)\n",
    "        self.W_K = nn.Linear(d_model, d_model)\n",
    "        self.W_V = nn.Linear(d_model, d_model)\n",
    "        \n",
    "        # 多头拼接成原维度后再进行一次线性变换\n",
    "        self.linear = nn.Linear(d_model, d_model, bias=False)\n",
    "    \n",
    "    # 这里如果是自注意力，那么qkv就是x，入参直接写x就行了，为啥搞了3个入参?????\n",
    "    def forward(self, q, k, v, mask=None):\n",
    "        assert q.ndim == 3, ' 形状要求(batch,words_len,d_model)'\n",
    "        assert k.ndim == 3, ' 形状要求(batch,words_len,d_model)'\n",
    "        assert v.ndim == 3, ' 形状要求(batch,words_len,d_model)'\n",
    "\n",
    "        \n",
    "        # 残差值，残差和规划应该放到外边，这里就凑活把\n",
    "        residual = q #把q当成入参了，放到做外边可以把带词向量的入参当入参\n",
    "        \n",
    "        # 批次\n",
    "        batch_size = q.size(0)\n",
    "\n",
    "        # 1.先线性变换\n",
    "        q = self.W_Q(q)\n",
    "        k = self.W_K(k)\n",
    "        v = self.W_V(v)\n",
    "        \n",
    "        # 分头前\n",
    "        # print(q)\n",
    "            \n",
    "        # 2.分头 \n",
    "        # (batch,words_len,d_model) -> (batch, words_len, n_head, d_k)\n",
    "        q = q.view(batch_size, -1, self.n_head, self.d_k)\n",
    "        # (batch, words_len, n_head, d_k) -> (batch, n_head, words_len, d_k) \n",
    "        q = q.transpose(1,2)\n",
    "        \n",
    "        # 分头后\n",
    "        # print(q)\n",
    "\n",
    "            \n",
    "        k = k.view(batch_size, -1, self.n_head, self.d_k)\n",
    "        k = k.transpose(1,2)\n",
    "        \n",
    "        v = v.view(batch_size, -1, self.n_head, self.d_k)\n",
    "        v = v.transpose(1,2)\n",
    "        \n",
    "        # 这里需要把掩码做扩维度吗？不可以自动广播吗 ??????\n",
    "        # 因为头是从(batch,words_len,d_model)变成了(batch,n_head,words_len,d_k)，所以掩码在头的维度扩一维\n",
    "        if mask is not None:\n",
    "            mask = mask.unsqueeze(1) \n",
    "        \n",
    "        # 计算注意力\n",
    "        context, softmax_scores = attention(q,k,v, mask=mask, dropout=self.dropout)\n",
    "        # print(context)\n",
    "        \n",
    "        # 掩码的形状和 注意力分数的形状， 注意力分数只关注词的个数\n",
    "        # print('mask.shape-> ',mask.shape, 'softmax_scores.shape->',  softmax_scores.shape)\n",
    "\n",
    "        # 把多头合并成一个头\n",
    "        # (batch, n_head, words_len, d_k) -> (batch, words_len, n_head ,d_k) -> (batch, words_len, n_head * d_k)\n",
    "        context = context.transpose(1,2).reshape(batch_size, -1, self.n_head * self.d_k)\n",
    "        # print(context)\n",
    "\n",
    "        # 然后再过一个线性层\n",
    "        context = self.linear(context)\n",
    "        \n",
    "        # print('residua-> ',residual)\n",
    "        # 残差和层归一化(这个操作最好放到外边)\n",
    "        return self.norm(residual+ context), softmax_scores \n",
    "\n",
    "    \n",
    "\n",
    "# 前馈神经网络\n",
    "class FeedForward(nn.Module):\n",
    "    # d_model: 输入维度  d_ff:输出维度\n",
    "    def __init__(self, d_model, d_ff, dropout=0):\n",
    "        super().__init__()\n",
    "        self.dropout = nn.Dropout(dropout)\n",
    "        self.w_1 = nn.Linear(d_model, d_ff)\n",
    "        self.w_2 = nn.Linear(d_ff, d_model)\n",
    "        self.norm = nn.LayerNorm(d_model)\n",
    "        \n",
    "    def forward(self, x):\n",
    "        assert x.ndim == 3 , '形状要求(batch, sentence_len, d_model)'\n",
    "        \n",
    "        residual = x\n",
    "\n",
    "        x = self.w_1(x).relu()\n",
    "        x = self.dropout(x)\n",
    "        # print('+'*60)\n",
    "\n",
    "        x = self.w_2(x)\n",
    "        \n",
    "        # 加上残差和归一化\n",
    "        return self.norm(residual + x)\n",
    "\n",
    "    \n",
    "## 编码子层\n",
    "class EncoderLayer(nn.Module):\n",
    "    def __init__(self, d_model, n_head, d_ff, dropout=0):\n",
    "        super().__init__()\n",
    "        self.mha = MultiHeadedAttention(d_model, n_head, dropout)\n",
    "        self.ff = FeedForward(d_model, d_ff, dropout)\n",
    "        \n",
    "    def forward(self, x, mask=None):\n",
    "        assert x.ndim == 3 , '形状要求(batch, sentence_len, d_model)'\n",
    "\n",
    "        # 1.先计算多头注意力\n",
    "        x,softmax_scores = self.mha(q=x, k=x, v=x, mask=mask)\n",
    "        # print(x.shape)\n",
    "        # 2.在进入前馈神经网络\n",
    "        return self.ff(x)\n",
    "    \n",
    "\n",
    "# 深度拷贝\n",
    "def clones(layer, N):\n",
    "    \"Produce N identical layers.\"\n",
    "    return nn.ModuleList([copy.deepcopy(layer) for _ in range(N)])\n",
    "\n",
    "## 编码层 好几个EncoderLayer\n",
    "class Encoder(nn.Module):\n",
    "    def __init__(self, layer, N):\n",
    "        super().__init__()\n",
    "        # 有N个EncoderLayer\n",
    "        self.layers = clones(layer,N)\n",
    "    \n",
    "    def forward(self, x, mask):\n",
    "        assert x.ndim == 3 , '形状要求(batch, sentence_len, d_model)'\n",
    "        \n",
    "        for layer in self.layers:\n",
    "            x = layer(x, mask)\n",
    "        \n",
    "        return x\n",
    "\n",
    "\n",
    "\n",
    "# 获取解码器中的句子掩码，不是批量掩码\n",
    "# words_len 单个句子长度(预测的目标值)\n",
    "def get_subsequent_mask(words_len):\n",
    "    # 形状(batch,words_len,words_len)\n",
    "    mask_shape = (1,words_len,words_len)\n",
    "    \n",
    "    # diagonal=1: 保留主对角线往上1行的数据(不包括主对角线)，不保留的数据都是0 \n",
    "    subsequent_mask = torch.triu(torch.ones(mask_shape), diagonal=1).type(torch.uint8)\n",
    "    \n",
    "    return subsequent_mask == 1\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "# 解码器子层\n",
    "class DecoderLayer(nn.Module):\n",
    "    def __init__(self, d_model, n_head, d_ff, dropout=0):\n",
    "        super().__init__()\n",
    "        # 自注意力，多头注意力，qkv同源\n",
    "        self.self_mha = MultiHeadedAttention(d_model=d_model, n_head=n_head, dropout=dropout)\n",
    "        # 交叉注意力，多头注意，q来自解码器，kv来自解码器\n",
    "        self.mha = MultiHeadedAttention(d_model=d_model, n_head=n_head, dropout=dropout)\n",
    "        # 前馈神经网络\n",
    "        self.feed_forward = FeedForward(d_model, d_ff, dropout)\n",
    "    \n",
    "    # tgt_mask 是解码层的mask，是叠加了批量掩码和单词掩码的   \n",
    "    # memory 解码器生成的，用来产生kv的中间量\n",
    "    # src_mask 解码器的批量掩码，交叉注意力时，q乘k的转置，需要把k后面的列屏蔽掉，跟解码器是同一个批量掩码\n",
    "    # training: 当前是否处于训练中\n",
    "    def forward(self, x, tgt_mask, memory, src_mask, training=True):\n",
    "        assert x.ndim == 3 , '形状要求(batch, sentence_len, d_model)'\n",
    "        assert tgt_mask.ndim == 3, '形状要求(batch, sentence_len, sentence_len)'\n",
    "        assert memory.ndim == 3 , '形状要求(batch, sentence_len, d_model)'\n",
    "        assert src_mask.ndim == 3 , '形状要求(batch, sentence_len, sentence_len)'\n",
    "            \n",
    "             \n",
    "        ##   掩码形状保持和入参一致  x形状(batch, sentence_len, d_model),x.size(1)表示词个数     ###\n",
    "        if training != True:\n",
    "            tgt_mask = tgt_mask[:, :, :x.size(1)]\n",
    "        ######################################################################################    \n",
    "            \n",
    "        # 1.自多头注意力  \n",
    "        x,softmax_scores = self.self_mha(q=x, k=x, v=x, mask=tgt_mask)\n",
    "        \n",
    "        \n",
    "        ## 如果当前是预测,此时x只需要传递最后一个词就可以了,因为预测词也是一个一个生成的, 但是在循环layer的时候上面的掩码也得变 ###\n",
    "        if training != True:\n",
    "            x = x[:, -1, :].unsqueeze(1)\n",
    "         ######################################################################################\n",
    "        \n",
    "            \n",
    "        # 2.交叉注意力,q有解码器生成， kv有解码器产生，\n",
    "        x,softmax_scores = self.mha(q=x, k=memory, v=memory, mask=src_mask)\n",
    "\n",
    "        \n",
    "        # 做前馈神经网络\n",
    "        return self.feed_forward(x)\n",
    "    \n",
    "# 解码器\n",
    "class Decoder(nn.Module):\n",
    "    def __init__(self, layer, N):\n",
    "        super().__init__()\n",
    "        # N个DecoderLayer\n",
    "        self.layers = clones(layer,N)\n",
    "    \n",
    "    def forward(self, x, tgt_mask, memory, src_mask, training=True):        \n",
    "        assert x.ndim == 3 , '形状要求(batch, sentence_len, d_model)'\n",
    "        assert tgt_mask.ndim == 3, '形状要求(batch, sentence_len, sentence_len)'\n",
    "        \n",
    "        assert memory.ndim == 3 , '形状要求(batch, sentence_len, d_model)'\n",
    "        assert src_mask.ndim == 3 , '形状要求(batch, sentence_len, sentence_len)'\n",
    "        \n",
    "        for layer in self.layers:\n",
    "            x = layer(x, tgt_mask, memory, src_mask, training)\n",
    "        \n",
    "        return x\n",
    "    \n",
    "\n",
    "class Generator(nn.Module):\n",
    "    # vocab_size: 目标语言的词表大小\n",
    "    def __init__(self, d_model, vocab_size):\n",
    "        super().__init__()\n",
    "        # \n",
    "        self.linear = nn.Linear(d_model, vocab_size)\n",
    "        \n",
    "    def forward(self, x):\n",
    "        assert x.ndim == 3 , '形状要求(batch, sentence_len, d_model)'\n",
    "\n",
    "        # x形状 (batch,words_len, d_model) ->(batch, words_len, vocab_size)\n",
    "        x = self.linear(x)\n",
    "        # return torch.softmax(x, dim=-1)\n",
    "        return x\n",
    "\n",
    "    \n",
    "# 模型\n",
    "class Transformer(nn.Module):\n",
    "    def __init__(self, encoder, decoder, src_embed, tgt_embed, generator):\n",
    "        super().__init__()\n",
    "        self.encoder = encoder\n",
    "        self.decoder = decoder\n",
    "        self.src_embed = src_embed\n",
    "        self.tgt_embed = tgt_embed\n",
    "        self.generator = generator\n",
    "    \n",
    "    def forward(self, src_x, src_mask, tgt_x, tgt_mask):\n",
    "        src_embed = self.src_embed(src_x)\n",
    "        tgt_embed = self.tgt_embed(tgt_x)\n",
    "        \n",
    "        memory = self.encoder(src_embed, src_mask)\n",
    "        output = self.decoder(tgt_embed, tgt_mask, memory, src_mask)\n",
    "        \n",
    "        return self.generator(output)\n",
    "\n",
    "    # 编码\n",
    "    def encode(self, src_x, src_mask):\n",
    "        return self.encoder(self.src_embed(src_x), src_mask)\n",
    "\n",
    "    # 解码\n",
    "    def decode(self, tgt_x, tgt_mask, memory, src_mask, training=True):\n",
    "        return self.decoder(self.tgt_embed(tgt_x),tgt_mask, memory, src_mask, training)\n",
    "    \n",
    "\n",
    "# 实例化模型    \n",
    "def make_model(src_vocab_size, tgt_vocab_size, d_model, n_head, d_ff, N, dropout):\n",
    "    \n",
    "    # 编码器\n",
    "    encoderLayer = EncoderLayer(d_model, n_head, d_ff, dropout)\n",
    "    encoder = Encoder(encoderLayer, N)\n",
    "   \n",
    "    # 解码层\n",
    "    decoderLayer = DecoderLayer(d_model, n_head, d_ff, dropout)\n",
    "    decoder = Decoder(decoderLayer, N)\n",
    "    \n",
    "    # 位置\n",
    "    position = PositionalEncoding(d_model=d_model, dropout=DROPOUT)\n",
    "\n",
    "    # 解码嵌入, Sequential可以让Embeddings执行完后再执行position\n",
    "    src_embed = nn.Sequential(Embeddings(src_vocab_size, d_model=d_model), position)\n",
    "    \n",
    "    # 编码嵌入\n",
    "    tgt_embed = nn.Sequential(Embeddings(tgt_vocab_size, d_model=d_model), position)\n",
    "    \n",
    "    # 生成器\n",
    "    generator = Generator(d_model, tgt_vocab_size)\n",
    "   \n",
    "    # 生成模型\n",
    "    model = Transformer(encoder, decoder, src_embed, tgt_embed, generator)\n",
    "    \n",
    "    # 初始化模型参数\n",
    "    for p in model.parameters():\n",
    "        if p.dim() > 1:\n",
    "            # 正态分布初始化\n",
    "            nn.init.xavier_uniform_(p)\n",
    "    \n",
    "    # 返回模型\n",
    "    return model\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "b6e11bed-878b-4c7d-ab88-4b37a039ee05",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([2, 4, 8])\n",
      "tensor([[[0.0633, 0.0712, 0.1933, 0.0571, 0.1171, 0.2794, 0.0425, 0.1761],\n",
      "         [0.0503, 0.0687, 0.2257, 0.0777, 0.1174, 0.2185, 0.0426, 0.1991],\n",
      "         [0.0541, 0.0662, 0.1884, 0.0632, 0.1085, 0.2600, 0.0446, 0.2149],\n",
      "         [0.0680, 0.0641, 0.1552, 0.0454, 0.0959, 0.3157, 0.0479, 0.2077]],\n",
      "\n",
      "        [[0.0653, 0.0737, 0.1399, 0.1017, 0.1368, 0.2984, 0.0340, 0.1503],\n",
      "         [0.0564, 0.0443, 0.3953, 0.0783, 0.1172, 0.2050, 0.0235, 0.0801],\n",
      "         [0.0539, 0.0356, 0.4700, 0.0827, 0.0974, 0.1640, 0.0227, 0.0736],\n",
      "         [0.0621, 0.0512, 0.3756, 0.0740, 0.1287, 0.2115, 0.0237, 0.0731]]],\n",
      "       grad_fn=<SoftmaxBackward0>)\n",
      "tensor([[5, 2, 5, 5],\n",
      "        [5, 2, 2, 2]])\n"
     ]
    }
   ],
   "source": [
    "###### 测试\n",
    "if __name__ == '__main__':\n",
    "    src_vocab_size = 6\n",
    "    tgt_vocab_size = 8\n",
    "    d_model = 6\n",
    "    n_head = 2\n",
    "    d_ff = 1024\n",
    "    N = 6 \n",
    "    dropout = 0\n",
    "    \n",
    "    model = make_model(src_vocab_size, tgt_vocab_size, d_model, n_head, d_ff, N, dropout)\n",
    "\n",
    "    # print(model)\n",
    "    # 输入数据\n",
    "    src_x = torch.tensor([\n",
    "        [1,2,3],\n",
    "        [3,5,0]\n",
    "    ])\n",
    "    # 解码层的掩码\n",
    "    src_mask = get_padding_mask(src_x, padding_idx=0)\n",
    "    \n",
    "    # 目标数据\n",
    "    tgt_x = torch.tensor([\n",
    "        [2,3,4,5],\n",
    "        [1,2,0,0]\n",
    "    ])\n",
    "    tgt_pad_mask = get_padding_mask(tgt_x, padding_idx=0)\n",
    "    subsequent_mask = get_subsequent_mask(words_len= tgt_x.size(-1))\n",
    "    # 句子掩码和pading掩码的叠加\n",
    "    tgt_mask = tgt_pad_mask | subsequent_mask\n",
    "    \n",
    "    \n",
    "    # 运算\n",
    "    predict = model(src_x, src_mask, tgt_x, tgt_mask)\n",
    "    print(predict.shape)\n",
    "    print(predict)\n",
    "    print(torch.argmax(predict, dim=-1))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "79bd04b6-0065-4525-9471-43eebd31a3f0",
   "metadata": {},
   "source": [
    "# 二、 ========= config.py ============"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 254,
   "id": "080bbf31-6e9b-4389-9079-9e03640058c0",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cpu\n",
      "MULTI_GPU: False\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import os\n",
    "\n",
    "BASE_PATH = os.path.dirname('.')\n",
    "\n",
    "# 训练数据文件路径\n",
    "TRAIN_PATH = os.path.join(BASE_PATH, './data/inputs/demo/train.json')\n",
    "# 校验数据文件路径\n",
    "VAL_PATH = os.path.join(BASE_PATH, './data/inputs/demo/val.json')\n",
    "\n",
    "\n",
    "# 存放中文词表的文件\n",
    "ZH_VOCAB_PATH = os.path.join(BASE_PATH, './data/vocab/zh.txt')\n",
    "# 存放英文词表的文件\n",
    "EN_VOCAB_PATH = os.path.join(BASE_PATH, './data/vocab/en.txt')\n",
    "\n",
    "# 特殊字符在词表中的id值\n",
    "PAD_ID = 0  # 屏蔽词id\n",
    "UNK_ID = 1  # 不知道的词id\n",
    "SOS_ID = 2  # 开始标记id\n",
    "EOS_ID = 3  # 结束标记id\n",
    "\n",
    "# 子层编码和解码个数\n",
    "N = 3\n",
    "# 词向量维度\n",
    "D_MODEL = 32\n",
    "# 头数\n",
    "N_HEAD = 2\n",
    "# feedforward 维度\n",
    "D_FF = 128\n",
    "\n",
    "DROPOUT = 0\n",
    "# # 批次\n",
    "BATCH_SIZE = 3\n",
    "BATCH_SIZE_GPU0 = 1\n",
    "\n",
    "# 学习率\n",
    "# LR = 0.0003\n",
    "# 训练次数\n",
    "EPOCHS = 100\n",
    "\n",
    "# 生成句子最大长度 \n",
    "MAX_LEN = 6\n",
    "\n",
    "# 标签平滑\n",
    "LABEL_SMOOTHING = 0.1\n",
    "\n",
    "# 运行设备\n",
    "DEVICE = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "\n",
    "# 多GPU\n",
    "MULTI_GPU = False\n",
    "if torch.cuda.device_count() > 1:\n",
    "    MULTI_GPU = True\n",
    "\n",
    "if __name__ == '__main__':\n",
    "    print(DEVICE)\n",
    "    print('MULTI_GPU:', MULTI_GPU)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1f8ff2f6-1b60-43be-8e45-8d56640da198",
   "metadata": {},
   "source": [
    "# 三、 =====  utils.py ====== 分词"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "f90a1c30-abb7-4f91-afb7-df6b50c62686",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'torch' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[3], line 80\u001b[0m\n\u001b[1;32m     77\u001b[0m         \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mGPU \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mi\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mgpu\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m, Memory Utilization: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mutilization\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m GB\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m     79\u001b[0m \u001b[38;5;66;03m# 调用\u001b[39;00m\n\u001b[0;32m---> 80\u001b[0m print_memory()\n\u001b[1;32m     81\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m--\u001b[39m\u001b[38;5;124m'\u001b[39m \u001b[38;5;241m*\u001b[39m \u001b[38;5;241m10\u001b[39m)\n\u001b[1;32m     84\u001b[0m \u001b[38;5;66;03m# 测试\u001b[39;00m\n",
      "Cell \u001b[0;32mIn[3], line 72\u001b[0m, in \u001b[0;36mprint_memory\u001b[0;34m()\u001b[0m\n\u001b[1;32m     70\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mprint_memory\u001b[39m():\n\u001b[1;32m     71\u001b[0m     \u001b[38;5;66;03m# 获取当前可用的GPU数量\u001b[39;00m\n\u001b[0;32m---> 72\u001b[0m     num_gpus \u001b[38;5;241m=\u001b[39m torch\u001b[38;5;241m.\u001b[39mcuda\u001b[38;5;241m.\u001b[39mdevice_count()\n\u001b[1;32m     73\u001b[0m     \u001b[38;5;66;03m# 遍历每个GPU，输出GPU的占用情况\u001b[39;00m\n\u001b[1;32m     74\u001b[0m     \u001b[38;5;28;01mfor\u001b[39;00m i \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mrange\u001b[39m(num_gpus):\n",
      "\u001b[0;31mNameError\u001b[0m: name 'torch' is not defined"
     ]
    }
   ],
   "source": [
    "################################# utils.py ################################\n",
    "############################################################################\n",
    "import jieba\n",
    "import re\n",
    "\n",
    "\n",
    "# 安装 sacrebleu\n",
    "# pip install sacrebleu\n",
    "import sacrebleu\n",
    "\n",
    "# 翻译评估\n",
    "# 预测的句子  hyp =  ['我爱吃苹果。', '这本书非常有趣。', '他是一位优秀的演员。']\n",
    "# 参考句子    refs = [['我喜欢吃苹果。', '我喜欢吃水果。'],\n",
    "#                    ['这本书很有意思。', '这本书很好玩。'],\n",
    "#                    ['他是一个出色的演员。', '他是一名杰出的演员。']]\n",
    "def bleu_score(hyp, refs):\n",
    "    bleu = sacrebleu.corpus_bleu(hyp, refs, tokenize='zh')\n",
    "    # 保留2位小数\n",
    "    return round(bleu.score, 2)\n",
    "\n",
    "\n",
    "# 中文分词\n",
    "def divided_zh(sentence):\n",
    "    return jieba.lcut(sentence)\n",
    "\n",
    "# 英文分词\n",
    "def divided_en(sentence):\n",
    "    # 匹配单词和标点符号\n",
    "    pattern = r'\\w+|[^\\w\\s]'\n",
    "    return re.findall(pattern, sentence)\n",
    "\n",
    "# 获取词表\n",
    "def get_vocab(lang='en'):\n",
    "    if lang == 'en':\n",
    "        file_path = EN_VOCAB_PATH\n",
    "    elif lang == 'zh':\n",
    "        file_path = ZH_VOCAB_PATH\n",
    "    \n",
    "    with open(file_path, encoding='utf-8') as file:\n",
    "        lines = file.read()\n",
    "        \n",
    "    id2vocab = lines.split('\\n')\n",
    "    vocab2id = {v:k for k,v in enumerate(id2vocab)}\n",
    "    \n",
    "    return id2vocab, vocab2id\n",
    "\n",
    "\n",
    "# ### 学习率调整策略 原论文\n",
    "# def lr_lambda_fn(step, model_size, factor, warmup):\n",
    "#     if step == 0:\n",
    "#         step = 1\n",
    "\n",
    "#     return factor * (\n",
    "#         model_size ** (-0.5) * min(step ** (-0.5), step * warmup ** (-1.5))\n",
    "#     )\n",
    "\n",
    "### 自定义策略 自定义\n",
    "def lr_lambda_fn(step, wramup):\n",
    "    lr = 0\n",
    "    if step <= wramup:\n",
    "        lr = step / wramup * 10\n",
    "    else:\n",
    "        lr = wramup / step * 10\n",
    "        \n",
    "    # print('lr-> ',lr)\n",
    "    return max(lr, 0.01)\n",
    "\n",
    "\n",
    "# 查看GPU显存占用情况\n",
    "def print_memory():\n",
    "    # 获取当前可用的GPU数量\n",
    "    num_gpus = torch.cuda.device_count()\n",
    "    # 遍历每个GPU，输出GPU的占用情况\n",
    "    for i in range(num_gpus):\n",
    "        gpu = torch.cuda.get_device_name(i)\n",
    "        utilization = round(torch.cuda.max_memory_allocated(i) / 1024**3, 2)  # 显存使用量（以GB为单位）\n",
    "        print(f\"GPU {i}: {gpu}, Memory Utilization: {utilization} GB\")\n",
    "\n",
    "# 调用\n",
    "print_memory()\n",
    "print('--' * 10)\n",
    "\n",
    "\n",
    "# 测试\n",
    "if __name__ == '__main__':\n",
    "    # print(divided_zh('我爱中国'))\n",
    "    # print(divided_en('I love china!'))\n",
    "    \n",
    "    # id2vocab, vocab2id = get_vocab('zh')\n",
    "    # print(id2vocab)\n",
    "    # print(vocab2id)\n",
    "    \n",
    "    target = '我喜欢阅读.'\n",
    "    # 分词\n",
    "    target_vocabs = divided_zh(target)\n",
    "    # 取出整个中文词表\n",
    "    zh_id2vocab, zh_vocab2id = get_vocab('zh')\n",
    "    \n",
    "    # 取句子对应的索引id形式  取每个词对应的id，如果这个词不存在则id默认为UNK_ID\n",
    "    src_x = [zh_vocab2id.get(word, UNK_ID) for word in target_vocabs]\n",
    "    print(src_x)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 291,
   "id": "2f654b51-794d-4eb9-865e-c07d0918cc6a",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "### 学习率调整策略\n",
    "from matplotlib import pyplot as plt\n",
    "\n",
    "def lr_lambda_fn(step, model_size, factor, warmup):\n",
    "    if step == 0:\n",
    "        step = 1\n",
    "\n",
    "    return factor * (\n",
    "        model_size ** (-0.5) * min(step ** (-0.5), step * warmup ** (-1.5))\n",
    "    )\n",
    "\n",
    "\n",
    "\n",
    "d_model = 512\n",
    "factor = 0.1\n",
    "warmup = 100\n",
    "\n",
    "rates = []\n",
    "steps = range(0, 1000)\n",
    "for step in steps:\n",
    "    r = lr_lambda_fn(step, d_model, factor, warmup)\n",
    "    rates.append(r)\n",
    "\n",
    "plt.plot(steps, rates)\n",
    "plt.show()\n",
    "\n",
    "\n",
    "### 自定义策略\n",
    "def lr_lambda_fn(step, wramup):\n",
    "    lr = 0\n",
    "    if step <= wramup:\n",
    "        lr = step / wramup * 5\n",
    "    else:\n",
    "        lr = wramup / step * 5\n",
    "    return max(lr, 0.1)\n",
    "\n",
    "rates = []\n",
    "total_epoch = 1000\n",
    "steps = range(total_epoch)\n",
    "for step in steps:\n",
    "    r = lr_lambda_fn(step, total_epoch/10)\n",
    "    rates.append(r)\n",
    "\n",
    "plt.plot(steps, rates)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 211,
   "id": "ce46b8eb-27bd-43ba-b0d0-9e194cb0226b",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# data_parallel.py    GPU负载均衡\n",
    "import torch\n",
    "from torch.nn.parallel.data_parallel import DataParallel\n",
    "from torch.nn.parallel.parallel_apply import parallel_apply\n",
    "from torch.nn.parallel._functions import Scatter\n",
    "\n",
    "def scatter(inputs, target_gpus, chunk_sizes, dim=0):\n",
    "    def scatter_map(obj):\n",
    "        if isinstance(obj, torch.Tensor):\n",
    "            try:\n",
    "                return Scatter.apply(target_gpus, chunk_sizes, dim, obj)\n",
    "            except Exception:\n",
    "                print('obj', obj.size())\n",
    "                print('dim', dim)\n",
    "                print('chunk_sizes', chunk_sizes)\n",
    "                quit()\n",
    "        if isinstance(obj, tuple) and len(obj) > 0:\n",
    "            return list(zip(*map(scatter_map, obj)))\n",
    "        if isinstance(obj, list) and len(obj) > 0:\n",
    "            return list(map(list, zip(*map(scatter_map, obj))))\n",
    "        if isinstance(obj, dict) and len(obj) > 0:\n",
    "            return list(map(type(obj), zip(*map(scatter_map, obj.items()))))\n",
    "        return [obj for targets in target_gpus]\n",
    "    try:\n",
    "        return scatter_map(inputs)\n",
    "    finally:\n",
    "        scatter_map = None\n",
    "\n",
    "def scatter_kwargs(inputs, kwargs, target_gpus, chunk_sizes, dim=0):\n",
    "    \"\"\"Scatter with support for kwargs dictionary\"\"\"\n",
    "    inputs = scatter(inputs, target_gpus, chunk_sizes, dim) if inputs else []\n",
    "    kwargs = scatter(kwargs, target_gpus, chunk_sizes, dim) if kwargs else []\n",
    "    if len(inputs) < len(kwargs):\n",
    "        inputs.extend([() for _ in range(len(kwargs) - len(inputs))])\n",
    "    elif len(kwargs) < len(inputs):\n",
    "        kwargs.extend([{} for _ in range(len(inputs) - len(kwargs))])\n",
    "    inputs = tuple(inputs)\n",
    "    kwargs = tuple(kwargs)\n",
    "    return inputs, kwargs\n",
    "\n",
    "class BalancedDataParallel(DataParallel):\n",
    "    def __init__(self, gpu0_bsz, *args, **kwargs):\n",
    "        self.gpu0_bsz = gpu0_bsz\n",
    "        super().__init__(*args, **kwargs)\n",
    "\n",
    "    def forward(self, *inputs, **kwargs):\n",
    "        if not self.device_ids:\n",
    "            return self.module(*inputs, **kwargs)\n",
    "        if self.gpu0_bsz == 0:\n",
    "            device_ids = self.device_ids[1:]\n",
    "        else:\n",
    "            device_ids = self.device_ids\n",
    "        inputs, kwargs = self.scatter(inputs, kwargs, device_ids)\n",
    "        if len(self.device_ids) == 1:\n",
    "            return self.module(*inputs[0], **kwargs[0])\n",
    "        replicas = self.replicate(self.module, self.device_ids)\n",
    "        if self.gpu0_bsz == 0:\n",
    "            replicas = replicas[1:]\n",
    "        outputs = self.parallel_apply(replicas, device_ids, inputs, kwargs)\n",
    "        return self.gather(outputs, self.output_device)\n",
    "\n",
    "    def parallel_apply(self, replicas, device_ids, inputs, kwargs):\n",
    "        return parallel_apply(replicas, inputs, kwargs, device_ids)\n",
    "\n",
    "    def scatter(self, inputs, kwargs, device_ids):\n",
    "        bsz = inputs[0].size(self.dim)\n",
    "        num_dev = len(self.device_ids)\n",
    "        gpu0_bsz = self.gpu0_bsz\n",
    "        bsz_unit = (bsz - gpu0_bsz) // (num_dev - 1)\n",
    "        if gpu0_bsz < bsz_unit:\n",
    "            chunk_sizes = [gpu0_bsz] + [bsz_unit] * (num_dev - 1)\n",
    "            delta = bsz - sum(chunk_sizes)\n",
    "            for i in range(delta):\n",
    "                chunk_sizes[i + 1] += 1\n",
    "            if gpu0_bsz == 0:\n",
    "                chunk_sizes = chunk_sizes[1:]\n",
    "        else:\n",
    "            return super().scatter(inputs, kwargs, device_ids)\n",
    "        return scatter_kwargs(inputs, kwargs, device_ids, chunk_sizes, dim=self.dim)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "249b56f4-41f6-43a4-8beb-144e1d207ece",
   "metadata": {},
   "source": [
    "# 四、==== data_processor.py ====== 构建词表, 数据预处理"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 212,
   "id": "28cf9521-a9c2-4b87-8189-722a8f58d01f",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "en_vocab_set count: 26\n",
      "zh_vocab_set count: 20\n"
     ]
    }
   ],
   "source": [
    "####################### data_precessor.py ############################\n",
    "######################################################################\n",
    "\n",
    "import json\n",
    "from collections import Counter\n",
    "\n",
    "# 生成词表\n",
    "def generate_vocab():\n",
    "    # 中文特殊词  [屏蔽词，不知道的词，开头，结尾]\n",
    "    en_vocab_set = ['<pad>','<unk>','<sos>','<eos>']\n",
    "    # 英文特殊词  [屏蔽词，不知道的词，开头，结尾]\n",
    "    zh_vocab_set = ['<pad>','<unk>','<sos>','<eos>']\n",
    "\n",
    "    en_vocab_list = []\n",
    "    zh_vocab_list = []\n",
    "\n",
    "    # 解析训练数据\n",
    "    with open(TRAIN_PATH, encoding='utf-8') as file:\n",
    "        lines = json.loads(file.read())\n",
    "        \n",
    "        for en_sentence, zh_sentence in lines:\n",
    "            # 收集英文分词后都数据\n",
    "            en_vocab_list += divided_en(en_sentence)\n",
    "            # 收集中文分词后都数据\n",
    "            zh_vocab_list += divided_zh(zh_sentence)\n",
    "    \n",
    "    \n",
    "    # 词表去重\n",
    "    # zh_vocab_list中的词去重排序  [('词1',5),('词2',3)]\n",
    "    zh_vocab_sort_kv = Counter(zh_vocab_list).most_common()\n",
    "    # 去重后的词表  ['词1', '词2', '词3']\n",
    "    zh_vocab_set += [k.lower() for k,v in zh_vocab_sort_kv]\n",
    "    \n",
    "    en_vocab_sort_kv = Counter(en_vocab_list).most_common()\n",
    "    # 去重后的词表  ['词1', '词2', '词3']\n",
    "    en_vocab_set += [k.lower() for k,v in en_vocab_sort_kv]\n",
    "    \n",
    "    print('en_vocab_set count:',len(en_vocab_set))\n",
    "    print('zh_vocab_set count:',len(zh_vocab_set))\n",
    "\n",
    "    \n",
    "    # Python join() 方法用于将序列中的元素以指定的字符连接生成一个新的字符串。\n",
    "    # 生成的词表写到文件中\n",
    "    with open(EN_VOCAB_PATH, 'w', encoding='utf-8') as file:\n",
    "        file.write('\\n'.join(en_vocab_set))\n",
    "        \n",
    "    with open(ZH_VOCAB_PATH, 'w', encoding='utf-8') as file:\n",
    "        file.write('\\n'.join(zh_vocab_set))\n",
    "    \n",
    "    \n",
    "# 生成词表    \n",
    "if __name__ == '__main__':\n",
    "    generate_vocab()\n",
    "    \n",
    "    \n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0f3a165d-ea49-4662-a460-7c7843fac69f",
   "metadata": {},
   "source": [
    "# 5 ======== data_loader.py ======== 数据加载"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 223,
   "id": "2edab71f-11df-4785-bbdf-666a288e7bdb",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "################### data_loader.py ####################\n",
    "#######################################################\n",
    "import torch.utils.data as data\n",
    "from torch.nn.utils.rnn import pad_sequence\n",
    "import json\n",
    "import torch\n",
    "\n",
    "\n",
    "class Dataset(data.Dataset):\n",
    "    def __init__(self, type='train'):\n",
    "        super().__init__()\n",
    "        if type == 'train':\n",
    "            file_path = TRAIN_PATH\n",
    "        elif type == 'val':\n",
    "            file_path = VAL_PATH\n",
    "            \n",
    "        with open(file_path, encoding='utf-8') as file:\n",
    "            self.lines = json.loads(file.read())\n",
    "            \n",
    "            # 词表\n",
    "            _, self.en_vocab2id = get_vocab('en')\n",
    "            _, self.zh_vocab2id = get_vocab('zh')\n",
    "\n",
    "    \n",
    "    def __len__(self):\n",
    "        return len(self.lines)\n",
    "            \n",
    "    \n",
    "    # 取第 index 单条样本\n",
    "    def __getitem__(self, index):\n",
    "        en_text, zh_text = self.lines[index]\n",
    "            \n",
    "        # 取出的句子进行分词，并转成索引表示\n",
    "        source = [self.en_vocab2id.get(word.lower(), UNK_ID) for word in divided_en(en_text)]\n",
    "        target = [self.zh_vocab2id.get(word.lower(), UNK_ID) for word in divided_zh(zh_text)]\n",
    "        \n",
    "        return source, target, zh_text\n",
    "\n",
    "    \n",
    "    # 数据对齐和整理\n",
    "    # batch是 Dataset 中返回的样本数据，有三个 source, target, zh_text\n",
    "    def collate_fn(self, batch):\n",
    "        \n",
    "        batch_source, batch_target, batch_tgt_text = zip(*batch)\n",
    "    \n",
    "        src_x = pad_sequence(sequences = [torch.LongTensor([SOS_ID]+src+[EOS_ID]) for src in batch_source],\n",
    "                          batch_first = True,\n",
    "                          padding_value = PAD_ID)\n",
    "        \n",
    "        # 批量句子掩码\n",
    "        src_mask = get_padding_mask(src_x, padding_idx=PAD_ID)\n",
    "    \n",
    "       \n",
    "        tgt_full = pad_sequence(sequences = [torch.LongTensor([SOS_ID]+src+[EOS_ID]) for src in batch_target],\n",
    "                          batch_first = True,\n",
    "                          padding_value = PAD_ID)\n",
    "        # 目标输入值 不包括句子的最后一个字符\n",
    "        tgt_x = tgt_full[:, :-1]\n",
    "        # 目标预测值 不包括句子的第一个字符\n",
    "        tgt_y = tgt_full[:, 1:]\n",
    "        \n",
    "        tgt_pad_mask = get_padding_mask(tgt_x, PAD_ID)\n",
    "        tgt_subsqueent_mask = get_subsequent_mask(words_len=tgt_x.size(-1))\n",
    "        tgt_mask = tgt_pad_mask | tgt_subsqueent_mask\n",
    "        \n",
    "        return src_x, src_mask, tgt_x, tgt_mask, tgt_y, batch_tgt_text \n",
    "    \n",
    "\n",
    "\n",
    "# train_dataset = Dataset('train')\n",
    "# train_loader = data.DataLoader(train_dataset, collate_fn=train_dataset.collate_fn, batch_size=BATCH_SIZE)\n",
    "\n",
    "# val_dataset = Dataset('val')\n",
    "# val_loader = data.DataLoader(val_dataset, collate_fn=val_dataset.collate_fn, batch_size=BATCH_SIZE)\n",
    "     \n",
    "\n",
    "# if __name__ == '__main__':\n",
    "#     dataset = Dataset('val')    \n",
    "    \n",
    "#     # 加上collate_fn函数后，loader的返回值就是这个函数的返回值了\n",
    "#     loader = data.DataLoader(dataset, collate_fn=dataset.collate_fn, batch_size=2)\n",
    "#     print(next(iter(loader)))\n",
    "    \n",
    "\n",
    "#     exit()\n",
    "#     # 解包操作\n",
    "#     batch = [\n",
    "#         [[1,2,3], ['a','b','c'], ['v','vb','vc']],\n",
    "#         [[4,5,6], ['d','e','f'], ['v','vb','vc']],\n",
    "#     ]\n",
    "#     a,b,c = zip(*batch) # 解包操作\n",
    "#     print(a)\n",
    "#     print(b)\n",
    "#     print(c)\n",
    "    \n",
    "#     print('*'*60)\n",
    "    \n",
    "#     # 等长填充\n",
    "#     batch_src = [\n",
    "#         [4,5,6],\n",
    "#         [6,7]\n",
    "#     ]\n",
    "\n",
    "#     # 句子等长填充，比如批量获取两个句子，每个句子的长度不一样，这里可以把短的用0填充\n",
    "#     src_pad = pad_sequence(sequences = [torch.LongTensor(src) for src in batch_src],\n",
    "#                           batch_first = True,\n",
    "#                           padding_value = 0)\n",
    "#     print(src_pad)\n",
    "    \n",
    "#     # 句子前后加上开头和末尾标识\n",
    "#     src_pad = pad_sequence(sequences = [torch.LongTensor([SOS_ID]+src+[EOS_ID]) for src in batch_src],\n",
    "#                           batch_first = True,\n",
    "#                           padding_value = 0)\n",
    "    \n",
    "#     print(src_pad)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "96066919-464d-473e-b935-10f0235ae623",
   "metadata": {},
   "source": [
    "# 6. ===== train.py ===== 训练文件"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "9a3b1791-ad06-4867-b58b-3da499d27493",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'EN_VOCAB_PATH' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[4], line 155\u001b[0m\n\u001b[1;32m    151\u001b[0m EPOCHS \u001b[38;5;241m=\u001b[39m \u001b[38;5;241m1000\u001b[39m\n\u001b[1;32m    154\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;18m__name__\u001b[39m \u001b[38;5;241m==\u001b[39m \u001b[38;5;124m'\u001b[39m\u001b[38;5;124m__main__\u001b[39m\u001b[38;5;124m'\u001b[39m:\n\u001b[0;32m--> 155\u001b[0m     en_id2vocab,_ \u001b[38;5;241m=\u001b[39m get_vocab(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124men\u001b[39m\u001b[38;5;124m'\u001b[39m)\n\u001b[1;32m    156\u001b[0m     zh_id2vocab,_ \u001b[38;5;241m=\u001b[39m get_vocab(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mzh\u001b[39m\u001b[38;5;124m'\u001b[39m)\n\u001b[1;32m    158\u001b[0m     \u001b[38;5;66;03m# 英文词表大小\u001b[39;00m\n",
      "Cell \u001b[0;32mIn[3], line 35\u001b[0m, in \u001b[0;36mget_vocab\u001b[0;34m(lang)\u001b[0m\n\u001b[1;32m     33\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mget_vocab\u001b[39m(lang\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124men\u001b[39m\u001b[38;5;124m'\u001b[39m):\n\u001b[1;32m     34\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m lang \u001b[38;5;241m==\u001b[39m \u001b[38;5;124m'\u001b[39m\u001b[38;5;124men\u001b[39m\u001b[38;5;124m'\u001b[39m:\n\u001b[0;32m---> 35\u001b[0m         file_path \u001b[38;5;241m=\u001b[39m EN_VOCAB_PATH\n\u001b[1;32m     36\u001b[0m     \u001b[38;5;28;01melif\u001b[39;00m lang \u001b[38;5;241m==\u001b[39m \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mzh\u001b[39m\u001b[38;5;124m'\u001b[39m:\n\u001b[1;32m     37\u001b[0m         file_path \u001b[38;5;241m=\u001b[39m ZH_VOCAB_PATH\n",
      "\u001b[0;31mNameError\u001b[0m: name 'EN_VOCAB_PATH' is not defined"
     ]
    }
   ],
   "source": [
    "#####################  train.py  ##########################\n",
    "###########################################################\n",
    "from torch.nn import CrossEntropyLoss\n",
    "from torch.optim import Adam\n",
    "from torch.optim.lr_scheduler import LambdaLR\n",
    "\n",
    "\n",
    "# 单轮训练\n",
    "def run_epoch(loader, model, loss_fun, optimizer=None):\n",
    "    # 本轮训练总损失\n",
    "    total_loss = 0\n",
    "    # 本轮 总批次\n",
    "    total_batchs = 0\n",
    "    \n",
    "    # print(next(iter(loader)))\n",
    "\n",
    "    # 加载数据并训练\n",
    "    for src_x, src_mask, tgt_x, tgt_mask, tgt_y, batch_tgt_text in loader:\n",
    "        src_x = src_x.to(DEVICE)\n",
    "        src_mask = src_mask.to(DEVICE)\n",
    "        tgt_x = tgt_x.to(DEVICE)\n",
    "        tgt_mask = tgt_mask.to(DEVICE)\n",
    "        tgt_y = tgt_y.to(DEVICE)\n",
    "        \n",
    "        # 模型输出 (batch, words_len, vocab_size) \n",
    "        # (批量个数(预测句子个数), 预测某个句子的单词个数, 预测的单词属于各个分类(vocab_size)的概率个数)\n",
    "        predict = model(src_x, src_mask, tgt_x, tgt_mask)\n",
    "        # print('predict.shape-> ', predict.shape)\n",
    "\n",
    "        # 形状转变，把批量维度去掉 (batch, words_len, vocab_size)  -> (words_len, vocab_size)\n",
    "        # 这样就变成了，预测的单词个数，以及单个单词属于各个分类的概率个数了\n",
    "        predict = predict.reshape(-1, predict.shape[-1])\n",
    "        \n",
    "        # 形状转变，(batch, target_size) -> (target_size) \n",
    "        # batch: 批次\n",
    "        # target_size:目标单词的个数, 里面放的是，目标单词的分类id\n",
    "        # 比如 目标词表有vocab_size个单词, tgt_y放的就是这个单词在词表中所属的id(经过交叉熵函数后，这个位置对应的单词就变成了概率只为1的目标值了)\n",
    "        tgt_y = tgt_y.reshape(-1)\n",
    "\n",
    "        # 计算损失\n",
    "        loss = loss_fun(predict, tgt_y)\n",
    "        \n",
    "        # 总损失\n",
    "        total_loss += loss.item()\n",
    "        total_batchs += 1\n",
    "        \n",
    "        # 反向传播\n",
    "        if optimizer:\n",
    "            # 梯度清零\n",
    "            optimizer.zero_grad()\n",
    "            # 计算梯度\n",
    "            loss.backward()\n",
    "            # 梯度更新\n",
    "            optimizer.step()\n",
    "        \n",
    "        # 返回平均损失\n",
    "        return total_loss / total_batchs\n",
    "    \n",
    "\n",
    "    \n",
    "# 逐字生成预测值\n",
    "def greedy_decode(model, src_x, src_mask, max_len):\n",
    "    # 如果是多GPU,则原始模型存放在 model.module中\n",
    "    model = model.module if MULTI_GPU else model\n",
    "    \n",
    "    # 录入的句子进行编码 \n",
    "    memory = model.encode(src_x, src_mask)\n",
    "    \n",
    "    # 初始每个批次的目标值   src_x.size(0):是批次\n",
    "    # 形状(batch, 单词个数)\n",
    "    tgt_x = torch.tensor([[SOS_ID]] * src_x.size(0))\n",
    "    \n",
    "    tgt_x = tgt_x.to(DEVICE)\n",
    "    \n",
    "    # 开始生成目标值\n",
    "    for _ in range(max_len):\n",
    "        # 解码其中的批量掩码，这里不需要句子掩码\n",
    "        tgt_mask = get_padding_mask(tgt_x,padding_idx=PAD_ID)\n",
    "        \n",
    "        # 解码 \n",
    "        # 训练时output形状 (batch, 预测过程中句子长度, 词表长度)\n",
    "        # 预测时output形状 (batch, 1, 词表长度)\n",
    "        output = model.decode(tgt_x, tgt_mask, memory, src_mask, training=model.training) \n",
    "       \n",
    "        # 用生成器取最后一个词  output最后形状 (batch, 1, 词表长度)\n",
    "        #  output[:, -1, :].unsqueeze(1)\n",
    "        output = model.generator(output)\n",
    "        # [batch, 1, 20]\n",
    "\n",
    "        # 获取生成词的词id   predict形状(批次, 1)  1表示生成一个词\n",
    "        predict = torch.argmax(output, dim=-1)\n",
    "        \n",
    "        # 所有生成的词拼接上  形状(batch, 单词个数)  tgt_x就是预测的结果\n",
    "        tgt_x = torch.concat([tgt_x, predict], dim=-1)\n",
    "       \n",
    "        # 碰到EOS_ID则结束预测, 如果有一个批次没结束则继续预测？\n",
    "        if torch.all(predict == EOS_ID).item():\n",
    "            break\n",
    "            \n",
    "    \n",
    "    # 中文词表\n",
    "    zh_id2vocab, _ = get_vocab('zh')\n",
    "    # 生成的句子放到如下\n",
    "    batch_tgt_text = []\n",
    "    \n",
    "    # 把预测的id，翻译成对应的词和句子，fangdao batch_tgt_text\n",
    "    for tgt in tgt_x:\n",
    "        # 单个句子\n",
    "        text = []\n",
    "        # tgt中放的是词id\n",
    "        for word_id in tgt:\n",
    "            if word_id == SOS_ID:\n",
    "                continue\n",
    "            elif word_id == EOS_ID:  # 碰到结束标识，改句子后面的解析就不要了\n",
    "                break\n",
    "\n",
    "            # 词id换成词，并放到text中\n",
    "            text.append(zh_id2vocab[word_id])\n",
    "\n",
    "        # 各个批次的句子放到 batch_tgt_text中\n",
    "        batch_tgt_text.append(''.join(text))\n",
    "        \n",
    "    # 返回生成的句子\n",
    "    return batch_tgt_text \n",
    "\n",
    "\n",
    " \n",
    "# 评估翻译效果    \n",
    "def evaluate(loader, model, max_len):\n",
    "    # 目标值，目标句子\n",
    "    tgt_sentence = []\n",
    "    # 翻译的句子\n",
    "    prob_sentence = []\n",
    "\n",
    "    for src_x, src_mask, tgt_x, tgt_mask, tgt_y, tgt_text in loader:\n",
    "        src_x = src_x.to(DEVICE)\n",
    "        src_mask = src_mask.to(DEVICE)\n",
    "        \n",
    "        # 翻译好的句子\n",
    "        batch_prob_text = greedy_decode(model, src_x, src_mask, max_len)\n",
    "\n",
    "        prob_sentence += batch_prob_text\n",
    "        tgt_sentence += tgt_text\n",
    "    \n",
    "    # 返回评估分数\n",
    "    return bleu_score(prob_sentence, [tgt_sentence]),prob_sentence,tgt_sentence\n",
    "\n",
    "# 学习率\n",
    "LR = 0.0001\n",
    "# 训练次数\n",
    "EPOCHS = 1000\n",
    "\n",
    "    \n",
    "if __name__ == '__main__':\n",
    "    en_id2vocab,_ = get_vocab('en')\n",
    "    zh_id2vocab,_ = get_vocab('zh')\n",
    "    \n",
    "    # 英文词表大小\n",
    "    SRC_VOCAB_SIZE = len(en_id2vocab)\n",
    "    # 中文词表大小\n",
    "    TGT_VOCAB_SIZE = len(zh_id2vocab)\n",
    "\n",
    "    # 实例化模型\n",
    "    model = make_model(SRC_VOCAB_SIZE, TGT_VOCAB_SIZE, D_MODEL, N_HEAD, D_FF, N, DROPOUT)\n",
    "    model = model.to(DEVICE)\n",
    "     # 加载已经训练好的模型\n",
    "    model.load_state_dict(torch.load('./model/best_model.pth', map_location=DEVICE))\n",
    "    \n",
    "    # 如果是多GPU\n",
    "    if MULTI_GPU:\n",
    "        # model = nn.DataParallel(model)\n",
    "        model = BalancedDataParallel(BATCH_SIZE_GPU0, model, dim=0)\n",
    "\n",
    "    \n",
    "    \n",
    "    ## 模型参数量\n",
    "    total_params = sum(p.numel() for p in model.parameters())\n",
    "    print('模型参数量: ',total_params)\n",
    "    \n",
    "    #损失函数和优化器\n",
    "    loss_fun = CrossEntropyLoss(ignore_index=PAD_ID, label_smoothing=LABEL_SMOOTHING)\n",
    "    optimizer = Adam(model.parameters(), lr=LR)\n",
    "    # 动态调整学习率\n",
    "    # lr_scheduler = LambdaLR(optimizer, lr_lambda=lambda step: lr_lambda_fn(step, 1))\n",
    "    \n",
    "    train_dataset = Dataset('train')\n",
    "    train_loader = data.DataLoader(train_dataset, shuffle=True, collate_fn=train_dataset.collate_fn, batch_size=BATCH_SIZE)\n",
    "    \n",
    "    val_dataset = Dataset('val')\n",
    "    val_loader = data.DataLoader(val_dataset, shuffle=True, collate_fn=val_dataset.collate_fn, batch_size=BATCH_SIZE)\n",
    "\n",
    "\n",
    "    #### 训练  #########\n",
    "    best_bleu_score = 74 # 最好的评估分数\n",
    "    \n",
    "    for i in range(EPOCHS):\n",
    "        ########### 训练模式 ##############\n",
    "        model.train()\n",
    "        train_loss = run_epoch(train_loader, model, loss_fun,optimizer)\n",
    "\n",
    "        # 动态调整学习率\n",
    "        # lr_scheduler.step()\n",
    "        current_lr = optimizer.param_groups[0]['lr']\n",
    "        print('当前学习率-> ',current_lr)\n",
    "        \n",
    "        ########### 验证流程 ##############\n",
    "        model.eval()\n",
    "        val_loss = run_epoch(val_loader, model, loss_fun,None)\n",
    "        # 评估\n",
    "        val_bleu_score,prob_sentence,tgt_sentence = evaluate(val_loader,model,MAX_LEN)\n",
    "        \n",
    "        # print('翻译: ',prob_sentence)\n",
    "        # print('目标: ',tgt_sentence)\n",
    "        print('>>eopch:',i, '; train_loss:',train_loss,'; val_loss:',val_loss, 'val_bleu_score:', val_bleu_score)\n",
    "        \n",
    "        # 如果当前评估分数好于 best_bleu_score，则保存模型\n",
    "        if val_bleu_score > best_bleu_score:\n",
    "            torch.save(model.state_dict(), './model/best_model.pth')\n",
    "            best_bleu_score = val_bleu_score\n",
    "            print('翻译: ',prob_sentence)\n",
    "            print('目标: ',tgt_sentence)\n",
    "            print('saveing-> ',train_loss, best_bleu_score)\n",
    "            \n",
    "            "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "90dd5573-c01b-4aa1-906e-d0e3d8adb60e",
   "metadata": {},
   "source": [
    "# 7.模型预测  predict.py"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 273,
   "id": "18a1a333-4ede-4b7a-b589-362e92c5de64",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cpu\n",
      "MULTI_GPU: False\n"
     ]
    }
   ],
   "source": [
    "################################# config.py ################################\n",
    "############################################################################\n",
    "\n",
    "import torch\n",
    "import os\n",
    "\n",
    "BASE_PATH = '/Users/mashunfeng/My/AI/'\n",
    "\n",
    "# 训练数据文件路径\n",
    "TRAIN_PATH = os.path.join(BASE_PATH, 'news/train.json')\n",
    "# 校验数据文件路径\n",
    "VAL_PATH = os.path.join(BASE_PATH, 'news/dev.json')\n",
    "\n",
    "\n",
    "# 存放中文词表的文件\n",
    "ZH_VOCAB_PATH = os.path.join('/Users/mashunfeng/My/AI/', 'zh.txt')\n",
    "# 存放英文词表的文件\n",
    "EN_VOCAB_PATH = os.path.join('/Users/mashunfeng/My/AI/', 'en.txt')\n",
    "\n",
    "# 特殊字符在词表中的id值\n",
    "PAD_ID = 0  # 屏蔽词id\n",
    "UNK_ID = 1  # 不知道的词id\n",
    "SOS_ID = 2  # 开始标记id\n",
    "EOS_ID = 3  # 结束标记id\n",
    "\n",
    "# 子层编码和解码个数\n",
    "N = 6\n",
    "# 词向量维度\n",
    "D_MODEL = 512\n",
    "# 头数\n",
    "N_HEAD = 8\n",
    "# feedforward 维度\n",
    "D_FF = 2048\n",
    "\n",
    "DROPOUT = 0.1\n",
    "# # 批次\n",
    "BATCH_SIZE = 350\n",
    "BATCH_SIZE_GPU0 = 50\n",
    "\n",
    "# 学习率\n",
    "LR = 1e-5\n",
    "# 训练次数\n",
    "EPOCHS = 10000\n",
    "\n",
    "# 生成句子最大长度 \n",
    "MAX_LEN = 50\n",
    "\n",
    "# 标签平滑\n",
    "LABEL_SMOOTHING = 0.1\n",
    "\n",
    "# 运行设备\n",
    "DEVICE = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "\n",
    "# 多GPU\n",
    "MULTI_GPU = False\n",
    "if torch.cuda.device_count() > 1:\n",
    "    MULTI_GPU = True\n",
    "\n",
    "if __name__ == '__main__':\n",
    "    print(DEVICE)\n",
    "    print('MULTI_GPU:', MULTI_GPU)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "09f7ed06-1851-48f1-859c-8d468b0057a5",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'get_vocab' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[2], line 3\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;18m__name__\u001b[39m \u001b[38;5;241m==\u001b[39m \u001b[38;5;124m'\u001b[39m\u001b[38;5;124m__main__\u001b[39m\u001b[38;5;124m'\u001b[39m:\n\u001b[0;32m----> 3\u001b[0m     en_id2vocab, en_vocab2id  \u001b[38;5;241m=\u001b[39m get_vocab(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124men\u001b[39m\u001b[38;5;124m'\u001b[39m)\n\u001b[1;32m      4\u001b[0m     zh_id2vocab, zh_vocab2id  \u001b[38;5;241m=\u001b[39m get_vocab(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mzh\u001b[39m\u001b[38;5;124m'\u001b[39m)\n\u001b[1;32m      6\u001b[0m     \u001b[38;5;66;03m# 英文词表大小\u001b[39;00m\n",
      "\u001b[0;31mNameError\u001b[0m: name 'get_vocab' is not defined"
     ]
    }
   ],
   "source": [
    "\n",
    "if __name__ == '__main__':\n",
    "    \n",
    "    en_id2vocab, en_vocab2id  = get_vocab('en')\n",
    "    zh_id2vocab, zh_vocab2id  = get_vocab('zh')\n",
    "    \n",
    "    # 英文词表大小\n",
    "    SRC_VOCAB_SIZE = len(en_id2vocab)\n",
    "    # 中文词表大小\n",
    "    TGT_VOCAB_SIZE = len(zh_id2vocab)\n",
    "\n",
    "    # 实例化模型\n",
    "    model = make_model(SRC_VOCAB_SIZE, TGT_VOCAB_SIZE, D_MODEL, N_HEAD, D_FF, N, DROPOUT)\n",
    "    model.to(DEVICE)\n",
    "    \n",
    "    model = BalancedDataParallel(BATCH_SIZE_GPU0, model, dim=0)\n",
    "\n",
    "    # 加载模型参数\n",
    "    model.load_state_dict(torch.load('/Users/mashunfeng/My/AI/best_model.pth', map_location=DEVICE))\n",
    "    model = model.module\n",
    "    model.eval()\n",
    "    \n",
    "    \n",
    "    src_texts = [\n",
    "        \"Having gone through the long years, people have come to understand more than ever before how important this doctrine is and how precious peace can be.\",\n",
    "        \"Everything is for the people, and everything relies on them.\",\n",
    "    ]\n",
    "\n",
    "    # 获取句子在词表中的id表示\n",
    "    src_tokens = [[en_vocab2id.get(word.lower(), UNK_ID) for word in divided_en(text)] \n",
    "                  for text in src_texts]\n",
    "    # 句子收尾加上开始和结束标识\n",
    "    src_tokens = [torch.LongTensor([SOS_ID]+src+[EOS_ID]) for src in src_tokens]\n",
    "    \n",
    "    # 长度不一致的用0填充\n",
    "    src_x = pad_sequence(src_tokens, batch_first=True, padding_value=PAD_ID)\n",
    "    print(src_x)\n",
    "    # 掩码\n",
    "    src_mask = get_padding_mask(src_x, PAD_ID)\n",
    "    \n",
    "    predict = greedy_decode(model, src_x, src_mask, max_len=10)\n",
    "    print(predict)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5dc33a72-ab24-4403-8d4d-6c749aea2f51",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
